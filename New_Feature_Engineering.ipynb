{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e38e9f553635fe04",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Nouveau Feature Engineering\n",
    "\n",
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4dd489bb7a586664",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T18:47:39.141709200Z",
     "start_time": "2024-04-16T18:47:39.128741400Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436af1e1249b5fa7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Réflexion\n",
    "\n",
    "Afin de pouvoir construire nos différents modèles, il est nécessaire de traiter les données et de s'assurer que les colonnes conservées sont à la fois exploitable au sein du jeu de données et à la fois que le jeu de test dispose d'assez de valeurs pertinentes. Ainsi, il est nécessaire de traiter toutes les années."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf0e7b731f9d838",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Fonctions utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "87da66a0ef9c95a7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T18:47:39.880829100Z",
     "start_time": "2024-04-16T18:47:39.867117300Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_info(data_frame: pd.DataFrame) -> dict:\n",
    "    col_info = {}\n",
    "    \n",
    "    for col in data_frame.columns:\n",
    "        possible_values = data_frame[col].unique()\n",
    "        na_count = data_frame[col].isna().sum()\n",
    "        obs_count = data_frame.shape[0]\n",
    "        rep_na = na_count / obs_count * 100\n",
    "        \n",
    "        col_info[col] = {\n",
    "            'possible_values': possible_values.tolist(),\n",
    "            'na_count': na_count,\n",
    "            'rep_na': rep_na\n",
    "        }\n",
    "        \n",
    "    return col_info\n",
    "\n",
    "def display_info(data_frame_test: pd.DataFrame, data_frame_train: pd.DataFrame) -> None:\n",
    "    dict_info_test = get_info(data_frame_test)\n",
    "    dict_info_train = get_info(data_frame_train)\n",
    "    \n",
    "    sorted_info_test = sorted(dict_info_test.items(), key=lambda x: x[1]['rep_na'], reverse=True)\n",
    "    sorted_info_train = sorted(dict_info_train.items(), key=lambda x: x[1]['rep_na'], reverse=True)       \n",
    "    \n",
    "    for col, info in sorted_info_test:\n",
    "        train_info = next((train_info for train_col, train_info in sorted_info_train if train_col == col), None)\n",
    "        print('*******')\n",
    "        print('TEST')\n",
    "        print(f\"- {col}: {info['possible_values']}.\")\n",
    "        print(f\"- {col}: {len(info['possible_values'])} valeurs uniques.\")\n",
    "        print(f\"- {col}: {info['rep_na']:.2f}%.\")\n",
    "        print('TRAIN')\n",
    "        print(f\"- {col}: {train_info['rep_na']:.2f}%.\")\n",
    "        print(f\"- {col}: {len(train_info['possible_values'])} valeurs uniques.\")\n",
    "        print(f\"- {col}: {train_info['possible_values']}.\")\n",
    "        print('')\n",
    "        \n",
    "def convert_to_int(time_str: str) -> int:\n",
    "    \"\"\"\n",
    "    Convert the string time in an integer value to allow intervals implementation\n",
    "    :param time_str: 'XX:XX', 'X:XX', 'XXX', 'X', X, XXX, ...\n",
    "    :return: an integer of the time according to the time format XX(hours)XX(minutes)\n",
    "    \"\"\"\n",
    "    if isinstance(time_str, str):\n",
    "        if ':' in time_str:\n",
    "            hours, minutes = map(int, time_str.split(':'))\n",
    "            return hours * 100 + minutes\n",
    "        else:\n",
    "            return int(time_str)\n",
    "    else:\n",
    "        return time_str\n",
    "    \n",
    "def generate_intervals(start, end, step) -> list[int]:\n",
    "    \"\"\"\n",
    "    Generate the intervals from the start to the end value by step\n",
    "    :param start: first value in the interval\n",
    "    :param end: last value in the interval\n",
    "    :param step: range between two categories\n",
    "    :return: list of intervals\n",
    "    \"\"\"\n",
    "    list_cat = []\n",
    "    for i in range(start, end, step):\n",
    "        list_cat.append((i, i + step))\n",
    "    return list_cat\n",
    "\n",
    "def map_to_simple_value(value: int, list_cat: list[int]) -> int:\n",
    "    \"\"\"\n",
    "    Function to map values to simple values based on intervals\n",
    "    :param list_cat: list of the intervals\n",
    "    :param value: value to map\n",
    "    :return: mapped value\n",
    "    \"\"\"\n",
    "    for i, interval in enumerate(list_cat):\n",
    "        if interval[0] <= value < interval[1]:\n",
    "            return simple_values[i]\n",
    "    return None \n",
    "\n",
    "def convert_float_to_int(data_frame: pd.DataFrame, col_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Convert the column type in the related dataframe from float to int\n",
    "    :param data_frame: dataframe where the column must be\n",
    "    :param col_name: column to parse\n",
    "    \"\"\"\n",
    "    data_frame[col_name] = data_frame[col_name].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c482a4f985d2ca",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2012/2013/2014/2015 "
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def feature_treatment_2012_to_2018(list_df: list[pd.DataFrame]) -> None:\n",
    "    for df in list_df:\n",
    "        # Suppression de colonnes\n",
    "        df.drop(columns=['adr', 'locp', 'num_veh', 'senc'], inplace=True)\n",
    "        \n",
    "        # Place : si pd.NA alors 0\n",
    "        df['place'] = df['place'].fillna(0)\n",
    "        \n",
    "        # lartpc/larrout : si > 100 (+ 100cm) conversion en m sinon conservation\n",
    "        df.loc[df['lartpc'] >= 100, 'lartpc'] /= 100\n",
    "        df.loc[df['larrout'] >= 100, 'larrout'] /= 100\n",
    "        \n",
    "        # nbv : si 4 ou + → devient/reste 4\n",
    "        df.loc[df['nbv'] >= 4, 'nbv'] = 4\n",
    "        \n",
    "        # prof/plan/surf/situ/etatp/manv/occutc/vosp : si 0 alors 1\n",
    "        df.loc[df['prof'] == 0, 'prof'] = 1\n",
    "        df.loc[df['plan'] == 0, 'plan'] = 1\n",
    "        df.loc[df['surf'] == 0, 'surf'] = 1\n",
    "        df.loc[df['situ'] == 0, 'situ'] = 1\n",
    "        df.loc[df['circ'] == 0, 'circ'] = 1\n",
    "        df.loc[df['etatp'] == 0, 'etatp'] = 1\n",
    "        df.loc[df['manv'] == 0, 'manv'] = 1\n",
    "        df.loc[df['occutc'] == 0, 'occutc'] = 1\n",
    "        df.loc[df['int'] == 0, 'int'] = 1\n",
    "        df.loc[df['vosp'] == 0, 'vosp'] = 1\n",
    "        \n",
    "        # env1 : 99 -> 2, 3 -> 1\n",
    "        df.loc[df['env1'] == 99, 'env1'] = 2\n",
    "        df.loc[df['env1'] == 3, 'env1'] = 1\n",
    "        \n",
    "        # trajet : 0 -> 9\n",
    "        df.loc[df['trajet'] == 0, 'trajet'] = 9\n",
    "        \n",
    "        # sexe/agg : 2 -> 1 \n",
    "        df.loc[df['sexe'] == 2, 'sexe'] = 0\n",
    "        df.loc[df['agg'] == 2, 'agg'] = 0\n",
    "        df.loc[df['nbv'] <= 0, 'nbv'] = pd.NA\n",
    "    \n",
    "        # an : 12 -> 2012, ...\n",
    "        df['an'] = df['Four_Digits']\n",
    "        \n",
    "        # hrmn : \n",
    "        def map_to_simple_value(value: int, list_cat: list[int]) -> int:\n",
    "            \"\"\"\n",
    "            Function to map values to simple values based on intervals\n",
    "            :param list_cat: list of the intervals\n",
    "            :param value: value to map\n",
    "            :return: mapped value\n",
    "            \"\"\"\n",
    "            for i, interval in enumerate(list_cat):\n",
    "                if interval[0] <= value < interval[1]:\n",
    "                    return simple_values[i]\n",
    "            return None \n",
    "        \n",
    "        \n",
    "        df['hrmn'] = df['hrmn'].apply(convert_to_int)\n",
    "        convert_float_to_int(df, 'hrmn')\n",
    "        intervals = generate_intervals(0, 2400, 100)\n",
    "        simple_values = list(range(len(intervals)))\n",
    "        df['hrmn'] = df['hrmn'].apply(map_to_simple_value, list_cat=intervals)\n",
    "    \n",
    "        # Suppression Four_Digits\n",
    "        df.drop(columns=['Four_Digits'], inplace=True)   "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T18:48:39.898618200Z",
     "start_time": "2024-04-16T18:48:39.872395800Z"
    }
   },
   "id": "cd156ce0af9816d7",
   "execution_count": 112
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bf2bace9b2c948e0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T18:48:45.368080400Z",
     "start_time": "2024-04-16T18:48:40.630656700Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_2012_2015 = pd.read_csv('Filtered_Data/TRAIN/DRAFT/train_data_filtered_2012_13_14_15.csv', sep=',', low_memory=False)\n",
    "test_data_2012_2015 = pd.read_csv('Filtered_Data/TEST/DRAFT/test_data_filtered_2012_13_14_15.csv', sep=',', low_memory=False)\n",
    "\n",
    "dfs = [train_data_2012_2015, test_data_2012_2015]\n",
    "feature_treatment_2012_to_2018(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 2012\n",
    "train_data_2012 = pd.read_csv('Filtered_Data/TRAIN/DRAFT/train_data_filtered_2012.csv', sep=',', low_memory=False)\n",
    "test_data_2012 = pd.read_csv('Filtered_Data/TEST/DRAFT/test_data_filtered_2012.csv', sep=',', low_memory=False)\n",
    "\n",
    "dfs = [train_data_2012, test_data_2012]\n",
    "feature_treatment_2012_to_2018(dfs)\n",
    "\n",
    "# 2013\n",
    "train_data_2013 = pd.read_csv('Filtered_Data/TRAIN/DRAFT/train_data_filtered_2013.csv', sep=',', low_memory=False)\n",
    "test_data_2013 = pd.read_csv('Filtered_Data/TEST/DRAFT/test_data_filtered_2013.csv', sep=',', low_memory=False)\n",
    "\n",
    "dfs = [train_data_2013, test_data_2013]\n",
    "feature_treatment_2012_to_2018(dfs)\n",
    "\n",
    "# 2014\n",
    "train_data_2014 = pd.read_csv('Filtered_Data/TRAIN/DRAFT/train_data_filtered_2014.csv', sep=',', low_memory=False)\n",
    "test_data_2014 = pd.read_csv('Filtered_Data/TEST/DRAFT/test_data_filtered_2014.csv', sep=',', low_memory=False)\n",
    "\n",
    "dfs = [train_data_2014, test_data_2014]\n",
    "feature_treatment_2012_to_2018(dfs)\n",
    "\n",
    "# 2015\n",
    "train_data_2015 = pd.read_csv('Filtered_Data/TRAIN/DRAFT/train_data_filtered_2015.csv', sep=',', low_memory=False)\n",
    "test_data_2015 = pd.read_csv('Filtered_Data/TEST/DRAFT/test_data_filtered_2015.csv', sep=',', low_memory=False)\n",
    "\n",
    "dfs = [train_data_2015, test_data_2015]\n",
    "feature_treatment_2012_to_2018(dfs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T18:57:42.260699900Z",
     "start_time": "2024-04-16T18:57:37.906402900Z"
    }
   },
   "id": "894e650dbd0ce105",
   "execution_count": 147
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2016"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9ce03822f9fb585"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def feature_treatment_2016(list_df: list[pd.DataFrame]) -> None:\n",
    "    for df in list_df:\n",
    "        # Suppression de colonnes\n",
    "        df.drop(columns=['adr', 'locp', 'num_veh'], inplace=True)\n",
    "        \n",
    "        # Place : si pd.NA alors 0\n",
    "        df['place'] = df['place'].fillna(0)\n",
    "        \n",
    "        # lartpc/larrout : si > 100 (+ 100cm) conversion en m sinon conservation\n",
    "        df.loc[df['lartpc'] >= 100, 'lartpc'] /= 100\n",
    "        df.loc[df['larrout'] >= 100, 'larrout'] /= 100\n",
    "        \n",
    "        # nbv : si 4 ou + → devient/reste 4\n",
    "        df.loc[df['nbv'] >= 4, 'nbv'] = 4\n",
    "        \n",
    "        # prof/plan/surf/situ/etatp/manv/occutc/vosp : si 0 alors 1\n",
    "        df.loc[df['prof'] == 0, 'prof'] = 1\n",
    "        df.loc[df['plan'] == 0, 'plan'] = 1\n",
    "        df.loc[df['surf'] == 0, 'surf'] = 1\n",
    "        df.loc[df['situ'] == 0, 'situ'] = 1\n",
    "        df.loc[df['circ'] == 0, 'circ'] = 1\n",
    "        df.loc[df['etatp'] == 0, 'etatp'] = 1\n",
    "        df.loc[df['manv'] == 0, 'manv'] = 1\n",
    "        df.loc[df['occutc'] == 0, 'occutc'] = 1\n",
    "        df.loc[df['int'] == 0, 'int'] = 1\n",
    "        df.loc[df['vosp'] == 0, 'vosp'] = 1\n",
    "        \n",
    "        # env1 : 99 -> 2, 3 -> 1\n",
    "        df.loc[df['env1'] == 99, 'env1'] = 2\n",
    "        df.loc[df['env1'] == 3, 'env1'] = 1\n",
    "        \n",
    "        # trajet : 0 -> 9\n",
    "        df.loc[df['trajet'] == 0, 'trajet'] = 9\n",
    "        \n",
    "        # senc/circ : 0 -> pd.NA\n",
    "        df.loc[df['senc'] == 0, 'senc'] = pd.NA\n",
    "        df.loc[df['circ'] == 0, 'circ'] = pd.NA\n",
    "        df.loc[df['nbv'] <= 0, 'nbv'] = pd.NA\n",
    "        \n",
    "        # sexe/agg : 2 -> 1 \n",
    "        df.loc[df['sexe'] == 2, 'sexe'] = 0\n",
    "        df.loc[df['agg'] == 2, 'agg'] = 0\n",
    "    \n",
    "        # an : 12 -> 2012, ...\n",
    "        df['an'] = df['Four_Digits']\n",
    "        \n",
    "        # hrmn : \n",
    "        \n",
    "        def map_to_simple_value(value: int, list_cat: list[int]) -> int:\n",
    "            \"\"\"\n",
    "            Function to map values to simple values based on intervals\n",
    "            :param list_cat: list of the intervals\n",
    "            :param value: value to map\n",
    "            :return: mapped value\n",
    "            \"\"\"\n",
    "            for i, interval in enumerate(list_cat):\n",
    "                if interval[0] <= value < interval[1]:\n",
    "                    return simple_values[i]\n",
    "            return None   \n",
    "        \n",
    "        \n",
    "        df['hrmn'] = df['hrmn'].apply(convert_to_int)\n",
    "        convert_float_to_int(df, 'hrmn')\n",
    "        intervals = generate_intervals(0, 2400, 100)\n",
    "        simple_values = list(range(len(intervals)))\n",
    "        df['hrmn'] = df['hrmn'].apply(map_to_simple_value, list_cat=intervals)\n",
    "    \n",
    "        # Suppression Four_Digits\n",
    "        df.drop(columns=['Four_Digits'], inplace=True)   "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T18:49:01.825433600Z",
     "start_time": "2024-04-16T18:49:01.761998500Z"
    }
   },
   "id": "85902255176168a0",
   "execution_count": 116
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data_2016 = pd.read_csv('Filtered_Data/TRAIN/DRAFT/train_data_filtered_2016.csv', sep=',', low_memory=False)\n",
    "test_data_2016 = pd.read_csv('Filtered_Data/TEST/DRAFT/test_data_filtered_2016.csv', sep=',', low_memory=False)\n",
    "\n",
    "dfs = [train_data_2016, test_data_2016]\n",
    "feature_treatment_2016(dfs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T18:49:04.352211800Z",
     "start_time": "2024-04-16T18:49:02.852275Z"
    }
   },
   "id": "ee81828dd8fb942b",
   "execution_count": 117
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2017"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ab9f41656747f6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def feature_treatment_2017(list_df: list[pd.DataFrame]) -> None:\n",
    "    for df in list_df:\n",
    "        # Suppression de colonnes\n",
    "        df.drop(columns=['adr', 'num_veh', 'actp', 'locp', 'etatp'], inplace=True)\n",
    "        \n",
    "        # Place : si pd.NA alors 0\n",
    "        df['place'] = df['place'].fillna(0)\n",
    "        \n",
    "        # lartpc/larrout : si > 100 (+ 100cm) conversion en m sinon conservation\n",
    "        df.loc[df['lartpc'] >= 100, 'lartpc'] /= 100\n",
    "        df.loc[df['larrout'] >= 100, 'larrout'] /= 100\n",
    "        \n",
    "        # nbv : si 4 ou + → devient/reste 4\n",
    "        df.loc[df['nbv'] >= 4, 'nbv'] = 4\n",
    "        df.loc[df['nbv'] <= 0, 'nbv'] = pd.NA\n",
    "        \n",
    "        # prof/plan/surf/situ/etatp/manv/occutc/vosp : si 0 alors 1\n",
    "        df.loc[df['prof'] == 0, 'prof'] = 1\n",
    "        df.loc[df['plan'] == 0, 'plan'] = 1\n",
    "        df.loc[df['surf'] == 0, 'surf'] = 1\n",
    "        df.loc[df['situ'] == 0, 'situ'] = 1\n",
    "        df.loc[df['circ'] == 0, 'circ'] = 1\n",
    "        df.loc[df['manv'] == 0, 'manv'] = 1\n",
    "        df.loc[df['occutc'] == 0, 'occutc'] = 1\n",
    "        df.loc[df['int'] == 0, 'int'] = 1\n",
    "        df.loc[df['vosp'] == 0, 'vosp'] = 1\n",
    "        \n",
    "        # env1 : 99 -> 2, 3 -> 1\n",
    "        df.loc[df['env1'] == 99, 'env1'] = 2\n",
    "        df.loc[df['env1'] == 3, 'env1'] = 1\n",
    "        \n",
    "        # trajet : 0 -> 9\n",
    "        df.loc[df['trajet'] == 0, 'trajet'] = 9\n",
    "        \n",
    "        # senc/circ : 0 -> pd.NA\n",
    "        df.loc[df['senc'] == 0, 'senc'] = pd.NA\n",
    "        df.loc[df['circ'] == 0, 'circ'] = pd.NA\n",
    "        \n",
    "        # sexe/agg : 2 -> 1 \n",
    "        df.loc[df['sexe'] == 2, 'sexe'] = 0\n",
    "        df.loc[df['agg'] == 2, 'agg'] = 0\n",
    "    \n",
    "        # an : 12 -> 2012, ...\n",
    "        df['an'] = df['Four_Digits']\n",
    "        \n",
    "        # hrmn : \n",
    "        def map_to_simple_value(value: int, list_cat: list[int]) -> int:\n",
    "            \"\"\"\n",
    "            Function to map values to simple values based on intervals\n",
    "            :param list_cat: list of the intervals\n",
    "            :param value: value to map\n",
    "            :return: mapped value\n",
    "            \"\"\"\n",
    "            for i, interval in enumerate(list_cat):\n",
    "                if interval[0] <= value < interval[1]:\n",
    "                    return simple_values[i]\n",
    "            return None       \n",
    "        \n",
    "        df['hrmn'] = df['hrmn'].apply(convert_to_int)\n",
    "        convert_float_to_int(df, 'hrmn')\n",
    "        intervals = generate_intervals(0, 2400, 100)\n",
    "        simple_values = list(range(len(intervals)))\n",
    "        df['hrmn'] = df['hrmn'].apply(map_to_simple_value, list_cat=intervals)\n",
    "        \n",
    "        # lat/long en mètres, normalisation\n",
    "        df['lat'] = df['lat'].astype(float)\n",
    "        df['long'] = df['long'].astype(float)\n",
    "        df.loc[df['lat'].notna(), 'lat'] /= 100000\n",
    "        df.loc[df['long'].notna(), 'long'] /= 100000\n",
    "    \n",
    "        # Suppression Four_Digits\n",
    "        df.drop(columns=['Four_Digits'], inplace=True)   "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T18:49:13.217912Z",
     "start_time": "2024-04-16T18:49:13.182029100Z"
    }
   },
   "id": "a972c8a6669de801",
   "execution_count": 118
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data_2017 = pd.read_csv('Filtered_Data/TRAIN/DRAFT/train_data_filtered_2017.csv', sep=',', low_memory=False)\n",
    "test_data_2017 = pd.read_csv('Filtered_Data/TEST/DRAFT/test_data_filtered_2017.csv', sep=',', low_memory=False)\n",
    "\n",
    "dfs = [train_data_2017, test_data_2017]\n",
    "feature_treatment_2017(dfs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T18:49:15.568705500Z",
     "start_time": "2024-04-16T18:49:13.920815800Z"
    }
   },
   "id": "4c7429b40142a362",
   "execution_count": 119
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2018"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b72399aa0a02efbb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def feature_treatment_2018(list_df: list[pd.DataFrame]) -> None:\n",
    "    for df in list_df:\n",
    "        # Suppression de colonnes\n",
    "        df.drop(columns=['adr', 'num_veh', 'locp', 'etatp'], inplace=True)\n",
    "        \n",
    "        # Place : si pd.NA alors 0\n",
    "        df['place'] = df['place'].fillna(0)\n",
    "        \n",
    "        # lartpc/larrout : si > 100 (+ 100cm) conversion en m sinon conservation\n",
    "        df.loc[df['lartpc'] >= 100, 'lartpc'] /= 100\n",
    "        df.loc[df['larrout'] >= 100, 'larrout'] /= 100\n",
    "        \n",
    "        # nbv : si 4 ou + → devient/reste 4\n",
    "        df.loc[df['nbv'] >= 4, 'nbv'] = 4\n",
    "        df.loc[df['nbv'] <= 0, 'nbv'] = pd.NA\n",
    "        \n",
    "        # prof/plan/surf/situ/etatp/manv/occutc/vosp : si 0 alors 1\n",
    "        df.loc[df['prof'] == 0, 'prof'] = 1\n",
    "        df.loc[df['plan'] == 0, 'plan'] = 1\n",
    "        df.loc[df['surf'] == 0, 'surf'] = 1\n",
    "        df.loc[df['situ'] == 0, 'situ'] = 1\n",
    "        df.loc[df['circ'] == 0, 'circ'] = 1\n",
    "        df.loc[df['manv'] == 0, 'manv'] = 1\n",
    "        df.loc[df['occutc'] == 0, 'occutc'] = 1\n",
    "        df.loc[df['int'] == 0, 'int'] = 1\n",
    "        df.loc[df['vosp'] == 0, 'vosp'] = 1\n",
    "        \n",
    "        # env1 : 99 -> 2, 3 -> 1\n",
    "        df.loc[df['env1'] == 99, 'env1'] = 2\n",
    "        df.loc[df['env1'] == 3, 'env1'] = 1\n",
    "        \n",
    "        # trajet : 0 -> 9\n",
    "        df.loc[df['trajet'] == 0, 'trajet'] = 9\n",
    "        \n",
    "        # senc/circ : 0 -> pd.NA\n",
    "        df.loc[df['senc'] == 0, 'senc'] = pd.NA\n",
    "        df.loc[df['circ'] == 0, 'circ'] = pd.NA\n",
    "        \n",
    "        # sexe/agg : 2 -> 1 \n",
    "        df.loc[df['sexe'] == 2, 'sexe'] = 0\n",
    "        df.loc[df['agg'] == 2, 'agg'] = 0\n",
    "    \n",
    "        # an : 12 -> 2012, ...\n",
    "        df['an'] = df['Four_Digits']\n",
    "        \n",
    "        # hrmn :\n",
    "        def map_to_simple_value(value: int, list_cat: list[int]) -> int:\n",
    "            \"\"\"\n",
    "            Function to map values to simple values based on intervals\n",
    "            :param list_cat: list of the intervals\n",
    "            :param value: value to map\n",
    "            :return: mapped value\n",
    "            \"\"\"\n",
    "            for i, interval in enumerate(list_cat):\n",
    "                if interval[0] <= value < interval[1]:\n",
    "                    return simple_values[i]\n",
    "            return None   \n",
    "        \n",
    "        \n",
    "        df['hrmn'] = df['hrmn'].apply(convert_to_int)\n",
    "        convert_float_to_int(df, 'hrmn')\n",
    "        intervals = generate_intervals(0, 2400, 100)\n",
    "        simple_values = list(range(len(intervals)))\n",
    "        df['hrmn'] = df['hrmn'].apply(map_to_simple_value, list_cat=intervals)\n",
    "    \n",
    "        # Suppression Four_Digits\n",
    "        df.drop(columns=['Four_Digits'], inplace=True)   "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T18:49:23.316602600Z",
     "start_time": "2024-04-16T18:49:23.274875900Z"
    }
   },
   "id": "9f1eb393d7e8f5a9",
   "execution_count": 121
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data_2018 = pd.read_csv('Filtered_Data/TRAIN/DRAFT/train_data_filtered_2016.csv', sep=',', low_memory=False)\n",
    "test_data_2018 = pd.read_csv('Filtered_Data/TEST/DRAFT/test_data_filtered_2016.csv', sep=',', low_memory=False)\n",
    "\n",
    "dfs = [train_data_2018, test_data_2018]\n",
    "feature_treatment_2018(dfs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T18:49:26.071950100Z",
     "start_time": "2024-04-16T18:49:24.029739300Z"
    }
   },
   "id": "1b1ad1aef56cf6d5",
   "execution_count": 122
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2019"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d0a2ffb2a9e3709"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def feature_treatment_2019(list_df: list[pd.DataFrame]) -> None:\n",
    "    for df in list_df:\n",
    "        # Suppression de colonnes\n",
    "        df.drop(columns=['adr', 'num_veh', 'id_vehicule_x', 'id_vehicule_y', 'voie', 'v1', 'locp'], inplace=True)\n",
    "        \n",
    "        # sexe/agg : 2 -> 1 \n",
    "        df.loc[df['sexe'] == 2, 'sexe'] = 0\n",
    "        df.loc[df['agg'] == 2, 'agg'] = 0\n",
    "        \n",
    "        # Place : si pd.NA alors 0\n",
    "        df['place'] = df['place'].fillna(10)\n",
    "        \n",
    "        # trajet : 0, -1 -> pd.NA \n",
    "        df['trajet'] = df['trajet'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['actp'] = df['actp'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['etatp'] = df['etatp'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['senc'] = df['senc'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['manv'] = df['manv'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['motor'] = df['motor'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['vma'] = df['vma'].replace({560: 50, 700: 70, 800: 80, 600: 60, -1: pd.NA, 5: 50, 3: 30, 4: 40, 1: 10, 0 : pd.NA, 2: 20, 12: 120, 6: 60})\n",
    "        \n",
    "        # -1 -> pd.NA\n",
    "        df['choc'] = df['choc'].replace({-1: pd.NA})\n",
    "        df['obs'] = df['obs'].replace({-1: pd.NA})\n",
    "        df['obsm'] = df['obsm'].replace({-1: pd.NA})\n",
    "        df['secu1'] = df['secu1'].replace({-1: pd.NA})\n",
    "        df['secu2'] = df['secu2'].replace({-1: pd.NA})\n",
    "        df['secu3'] = df['secu3'].replace({-1: pd.NA})\n",
    "        df['circ'] = df['circ'].replace({-1: pd.NA})\n",
    "        df['atm'] = df['atm'].replace({-1: pd.NA})\n",
    "        df['col'] = df['col'].replace({-1: pd.NA})\n",
    "        df['vosp'] = df['vosp'].replace({-1: pd.NA})\n",
    "        df['prof'] = df['prof'].replace({-1: pd.NA})\n",
    "        df['plan'] = df['plan'].replace({-1: pd.NA})\n",
    "        df['surf'] = df['surf'].replace({-1: pd.NA})\n",
    "        df['infra'] = df['infra'].replace({-1: pd.NA})\n",
    "        df['situ'] = df['situ'].replace({-1: pd.NA})\n",
    "        \n",
    "        # 0 -> pd.NA\n",
    "        df['catv'] = df['catv'].replace({0: pd.NA})\n",
    "                \n",
    "        # lat/long en mètres, normalisation\n",
    "        df['lat'] = df['lat'].str.replace(',', '.').astype(float)\n",
    "        df['long'] = df['long'].str.replace(',', '.').astype(float)\n",
    "        df.loc[df['lat'].notna(), 'lat'] /= 100\n",
    "        df.loc[df['long'].notna(), 'long'] /= 100\n",
    "        \n",
    "        # nbv : si 4 ou + → devient/reste 4\n",
    "        df.loc[df['nbv'] >= 4, 'nbv'] = 4\n",
    "        df.loc[df['nbv'] <= 0, 'nbv'] = pd.NA       \n",
    "        \n",
    "        # Remove paranthesis\n",
    "        df['pr'] = df['pr'].str.replace(r'\\(|\\)', '')\n",
    "        df['pr1'] = df['pr1'].str.replace(r'\\(|\\)', '')\n",
    "        df['pr'] = df['pr'].replace('-1', pd.NA)\n",
    "        df['pr1'] = df['pr1'].replace('-1', pd.NA)\n",
    "        \n",
    "        # an : 12 -> 2012, ...\n",
    "        df['an'] = df['Four_Digits']\n",
    "        \n",
    "        # hrmn : \n",
    "        def map_to_simple_value(value: int, list_cat: list[int]) -> int:\n",
    "            \"\"\"\n",
    "            Function to map values to simple values based on intervals\n",
    "            :param list_cat: list of the intervals\n",
    "            :param value: value to map\n",
    "            :return: mapped value\n",
    "            \"\"\"\n",
    "            for i, interval in enumerate(list_cat):\n",
    "                if interval[0] <= value < interval[1]:\n",
    "                    return simple_values[i]\n",
    "            return None       \n",
    "        \n",
    "        df['hrmn'] = df['hrmn'].apply(convert_to_int)\n",
    "        convert_float_to_int(df, 'hrmn')\n",
    "        intervals = generate_intervals(0, 2400, 100)\n",
    "        simple_values = list(range(len(intervals)))\n",
    "        df['hrmn'] = df['hrmn'].apply(map_to_simple_value, list_cat=intervals)\n",
    "        \n",
    "        # Suppression Four_Digits\n",
    "        df.drop(columns=['Four_Digits'], inplace=True)  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T18:49:35.336547Z",
     "start_time": "2024-04-16T18:49:35.314627800Z"
    }
   },
   "id": "3087420c7cc967c",
   "execution_count": 123
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data_2019 = pd.read_csv('Filtered_Data/TRAIN/DRAFT/train_data_filtered_2019.csv', sep=',', low_memory=False)\n",
    "test_data_2019 = pd.read_csv('Filtered_Data/TEST/DRAFT/test_data_filtered_2019.csv', sep=',', low_memory=False)\n",
    "\n",
    "dfs = [train_data_2019, test_data_2019]\n",
    "feature_treatment_2019(dfs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T18:49:40.681615400Z",
     "start_time": "2024-04-16T18:49:36.100499300Z"
    }
   },
   "id": "13d1661451225d7f",
   "execution_count": 124
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2020 - 2021"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81c45cde46695a28"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def feature_treatment_2020_to_2021(list_df: list[pd.DataFrame]) -> None:\n",
    "    for df in list_df:\n",
    "        # Suppression de colonnes\n",
    "        df.drop(columns=['adr', 'num_veh', 'id_vehicule_x', 'id_vehicule_y', 'locp', 'voie', 'v1'], inplace=True)\n",
    "        \n",
    "        # VMA\n",
    "        df['vma'] = df['vma'].replace({-1: pd.NA, 1:10, 2:20, 5:50, 3:30, 6:60, 300:30, 7:70, 700: 70, 8: 80, 900: 90, 520: pd.NA, 901 : pd.NA, 9: 90, 501: pd.NA, 770: pd.NA, 12: 120})\n",
    "        \n",
    "        # sexe/agg : 2 -> 1 \n",
    "        df.loc[df['sexe'] == 2, 'sexe'] = 0\n",
    "        df.loc[df['agg'] == 2, 'agg'] = 0\n",
    "        \n",
    "        # an : 12 -> 2012, ...\n",
    "        df['an'] = df['Four_Digits']\n",
    "        \n",
    "        # lartpc/larrout : si > 100 (+ 100cm) conversion en m sinon conservation\n",
    "        df['larrout'] = df['larrout'].str.replace(',', '.').astype(float)\n",
    "        df.loc[df['larrout'] >= 10, 'larrout'] /= 10\n",
    "        \n",
    "        # Place : si -1 pd.NA\n",
    "        df['place'] = df['place'].replace({-1: pd.NA})\n",
    "        df['sexe'] = df['sexe'].replace({-1: pd.NA})\n",
    "        df['obs'] = df['obs'].replace({-1: pd.NA})\n",
    "        df['obsm'] = df['obsm'].replace({-1: pd.NA})\n",
    "        df['choc'] = df['choc'].replace({-1: pd.NA})\n",
    "        df['lum'] = df['lum'].replace({-1: pd.NA})\n",
    "        df['int'] = df['int'].replace({-1: pd.NA})\n",
    "        df['atm'] = df['atm'].replace({-1: pd.NA})\n",
    "        df['col'] = df['col'].replace({-1: pd.NA})\n",
    "        df['circ'] = df['circ'].replace({-1: pd.NA})\n",
    "        df['vosp'] = df['vosp'].replace({-1: pd.NA})\n",
    "        df['prof'] = df['prof'].replace({-1: pd.NA})\n",
    "        df['plan'] = df['plan'].replace({-1: pd.NA})\n",
    "        df['surf'] = df['surf'].replace({-1: pd.NA})\n",
    "        df['infra'] = df['infra'].replace({-1: pd.NA})\n",
    "        df['situ'] = df['situ'].replace({-1: pd.NA})\n",
    "        df['secu1'] = df['secu1'].replace({-1: pd.NA})\n",
    "        df['secu2'] = df['secu2'].replace({-1: pd.NA})\n",
    "        df['secu3'] = df['secu3'].replace({-1: pd.NA})\n",
    "        \n",
    "        # trajet : 0, -1 -> pd.NA \n",
    "        df['trajet'] = df['trajet'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['larrout'] = df['larrout'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['actp'] = df['actp'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['etatp'] = df['etatp'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['senc'] = df['senc'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['catv'] = df['catv'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['manv'] = df['manv'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['com'] = df['com'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['dep'] = df['dep'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['motor'] = df['motor'].replace({0: pd.NA, -1: pd.NA})\n",
    "        \n",
    "        # hrmn : \n",
    "        def map_to_simple_value(value: int, list_cat: list[int]) -> int:\n",
    "            \"\"\"\n",
    "            Function to map values to simple values based on intervals\n",
    "            :param list_cat: list of the intervals\n",
    "            :param value: value to map\n",
    "            :return: mapped value\n",
    "            \"\"\"\n",
    "            for i, interval in enumerate(list_cat):\n",
    "                if interval[0] <= value < interval[1]:\n",
    "                    return simple_values[i]\n",
    "            return None \n",
    "        \n",
    "        \n",
    "        df['hrmn'] = df['hrmn'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['hrmn'] = df['hrmn'].apply(convert_to_int)\n",
    "        convert_float_to_int(df, 'hrmn')\n",
    "        intervals = generate_intervals(0, 2400, 100)\n",
    "        simple_values = list(range(len(intervals)))\n",
    "        df['hrmn'] = df['hrmn'].apply(map_to_simple_value, list_cat=intervals)\n",
    "        \n",
    "        # lat/long en mètres, normalisation\n",
    "        df['lat'] = df['lat'].str.replace(',', '.').astype(float)\n",
    "        df['long'] = df['long'].str.replace(',', '.').astype(float)\n",
    "        df.loc[df['lat'].notna(), 'lat'] /= 100\n",
    "        df.loc[df['long'].notna(), 'long'] /= 100\n",
    "        \n",
    "        # nbv : si 4 ou + → devient/reste 4\n",
    "        df.loc[df['nbv'] >= 4, 'nbv'] = 4\n",
    "        df.loc[df['nbv'] <= 0, 'nbv'] = pd.NA   \n",
    "        \n",
    "        # Remove paranthesis\n",
    "        df['pr'] = df['pr'].str.replace(r'\\(|\\)', '')\n",
    "        df['pr1'] = df['pr1'].str.replace(r'\\(|\\)', '')\n",
    "        df['pr'] = df['pr'].replace('-1', pd.NA)\n",
    "        df['pr1'] = df['pr1'].replace('-1', pd.NA)\n",
    "        \n",
    "        # Suppression Four_Digits\n",
    "        df.drop(columns=['Four_Digits'], inplace=True)  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T18:51:12.845617300Z",
     "start_time": "2024-04-16T18:51:12.814140900Z"
    }
   },
   "id": "b25710d3eeba23c7",
   "execution_count": 131
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data_2020_21= pd.read_csv('Filtered_Data/TRAIN/DRAFT/train_data_filtered_2020_21.csv', sep=',', low_memory=False)\n",
    "test_data_2020_21 = pd.read_csv('Filtered_Data/TEST/DRAFT/test_data_filtered_2020_21.csv', sep=',', low_memory=False)\n",
    "\n",
    "dfs = [test_data_2020_21, train_data_2020_21]\n",
    "feature_treatment_2020_to_2021(dfs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T18:51:20.316803800Z",
     "start_time": "2024-04-16T18:51:13.292208200Z"
    }
   },
   "id": "3467b9aeacd7fe69",
   "execution_count": 132
  },
  {
   "cell_type": "markdown",
   "id": "ab600699349c1ef4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2022"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def feature_treatment_2022(list_df: list[pd.DataFrame]) -> None:\n",
    "    for df in list_df:\n",
    "        # Suppression de colonnes\n",
    "        df.drop(columns=['adr', 'num_veh', 'id_vehicule_x', 'id_vehicule_y', 'locp', 'voie', 'v1'], inplace=True)\n",
    "        \n",
    "        # VMA\n",
    "        df['vma'] = df['vma'].replace({-1: pd.NA, 1:10, 2:20, 5:50, 3:30, 6:60, 300:30, 7:70, 700: 70, 8: 80, 900: 90, 520: pd.NA, 901 : pd.NA, 9: 90, 501: pd.NA, 770: pd.NA, 12: 120})\n",
    "        \n",
    "        # sexe/agg : 2 -> 1 \n",
    "        df.loc[df['sexe'] == 2, 'sexe'] = 0\n",
    "        df.loc[df['agg'] == 2, 'agg'] = 0\n",
    "        \n",
    "        # an : 12 -> 2012, ...\n",
    "        df['an'] = df['Four_Digits']\n",
    "        \n",
    "        # lartpc/larrout : si > 100 (+ 100cm) conversion en m sinon conservation\n",
    "        df['larrout'] = df['larrout'].str.replace(',', '.').astype(float)\n",
    "        df.loc[df['larrout'] >= 10, 'larrout'] /= 10\n",
    "        \n",
    "        # Place : si -1 pd.NA\n",
    "        df['place'] = df['place'].replace({-1: pd.NA})\n",
    "        df['sexe'] = df['sexe'].replace({-1: pd.NA})\n",
    "        df['obs'] = df['obs'].replace({-1: pd.NA})\n",
    "        df['obsm'] = df['obsm'].replace({-1: pd.NA})\n",
    "        df['choc'] = df['choc'].replace({-1: pd.NA})\n",
    "        df['lum'] = df['lum'].replace({-1: pd.NA})\n",
    "        df['int'] = df['int'].replace({-1: pd.NA})\n",
    "        df['atm'] = df['atm'].replace({-1: pd.NA})\n",
    "        df['col'] = df['col'].replace({-1: pd.NA})\n",
    "        df['circ'] = df['circ'].replace({-1: pd.NA})\n",
    "        df['vosp'] = df['vosp'].replace({-1: pd.NA})\n",
    "        df['prof'] = df['prof'].replace({-1: pd.NA})\n",
    "        df['plan'] = df['plan'].replace({-1: pd.NA})\n",
    "        df['surf'] = df['surf'].replace({-1: pd.NA})\n",
    "        df['infra'] = df['infra'].replace({-1: pd.NA})\n",
    "        df['situ'] = df['situ'].replace({-1: pd.NA})\n",
    "        df['secu1'] = df['secu1'].replace({-1: pd.NA})\n",
    "        df['secu2'] = df['secu2'].replace({-1: pd.NA})\n",
    "        df['secu3'] = df['secu3'].replace({-1: pd.NA})\n",
    "        \n",
    "        # trajet : 0, -1 -> pd.NA \n",
    "        df['trajet'] = df['trajet'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['larrout'] = df['larrout'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['actp'] = df['actp'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['etatp'] = df['etatp'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['senc'] = df['senc'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['catv'] = df['catv'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['manv'] = df['manv'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['com'] = df['com'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['dep'] = df['dep'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['motor'] = df['motor'].replace({0: pd.NA, -1: pd.NA})\n",
    "        \n",
    "        # hrmn : \n",
    "        def map_to_simple_value(value: int, list_cat: list[int]) -> int:\n",
    "            \"\"\"\n",
    "            Function to map values to simple values based on intervals\n",
    "            :param list_cat: list of the intervals\n",
    "            :param value: value to map\n",
    "            :return: mapped value\n",
    "            \"\"\"\n",
    "            for i, interval in enumerate(list_cat):\n",
    "                if interval[0] <= value < interval[1]:\n",
    "                    return simple_values[i]\n",
    "            return None \n",
    "        \n",
    "        \n",
    "        df['hrmn'] = df['hrmn'].replace({0: pd.NA, -1: pd.NA})\n",
    "        df['hrmn'] = df['hrmn'].apply(convert_to_int)\n",
    "        convert_float_to_int(df, 'hrmn')\n",
    "        intervals = generate_intervals(0, 2400, 100)\n",
    "        simple_values = list(range(len(intervals)))\n",
    "        df['hrmn'] = df['hrmn'].apply(map_to_simple_value, list_cat=intervals)\n",
    "        \n",
    "        # lat/long en mètres, normalisation\n",
    "        df['lat'] = df['lat'].str.replace(',', '.').astype(float)\n",
    "        df['long'] = df['long'].str.replace(',', '.').astype(float)\n",
    "        df.loc[df['lat'].notna(), 'lat'] /= 100\n",
    "        df.loc[df['long'].notna(), 'long'] /= 100\n",
    "        \n",
    "        # nbv : si 4 ou + → devient/reste 4\n",
    "        df['nbv'] = df['nbv'].replace({\"#ERREUR\" : 0})\n",
    "        df['nbv'] = df['nbv'].astype(float)\n",
    "        df.loc[df['nbv'] >= 4, 'nbv'] = 4\n",
    "        df.loc[df['nbv'] <= 0, 'nbv'] = pd.NA   \n",
    "        \n",
    "        # Remove paranthesis\n",
    "        df['pr'] = df['pr'].str.replace(r'\\(|\\)', '')\n",
    "        df['pr1'] = df['pr1'].str.replace(r'\\(|\\)', '')\n",
    "        df['pr'] = df['pr'].replace('-1', pd.NA)\n",
    "        df['pr1'] = df['pr1'].replace('-1', pd.NA)\n",
    "        \n",
    "        # Suppression Four_Digits\n",
    "        df.drop(columns=['Four_Digits'], inplace=True)  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T18:53:31.864878Z",
     "start_time": "2024-04-16T18:53:31.833988600Z"
    }
   },
   "id": "7ab447511ff07544",
   "execution_count": 144
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data_2022 = pd.read_csv('Filtered_Data/TRAIN/DRAFT/train_data_filtered_2022.csv', sep=',', low_memory=False)\n",
    "test_data_2022 = pd.read_csv('Filtered_Data/TEST/DRAFT/test_data_filtered_2022.csv', sep=',', low_memory=False)\n",
    "\n",
    "dfs = [test_data_2022, train_data_2022]\n",
    "feature_treatment_2022(dfs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T18:53:35.634646300Z",
     "start_time": "2024-04-16T18:53:32.455462500Z"
    }
   },
   "id": "e078d98e154fc2ab",
   "execution_count": 145
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for year in range(2012, 2023):\n",
    "    test_data_var_name = f\"test_data_{year}\"\n",
    "    train_data_var_name = f\"train_data_{year}\"\n",
    "    \n",
    "    if test_data_var_name in globals():\n",
    "        test_data = globals()[test_data_var_name]\n",
    "        test_data.to_csv(f\"Filtered_Data/TEST/DRAFT_2/{test_data_var_name}.csv\", index=False)\n",
    "        \n",
    "    if train_data_var_name in globals():\n",
    "        train_data = globals()[train_data_var_name]\n",
    "        train_data.to_csv(f\"Filtered_Data/TRAIN/DRAFT_2/{train_data_var_name}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T18:58:12.518391300Z",
     "start_time": "2024-04-16T18:57:48.383566700Z"
    }
   },
   "id": "775721bc49a7ed54",
   "execution_count": 148
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TRAIN/TEST 2012/2013/2014/2015\n",
    "train_data_2012_2015.to_csv('Filtered_Data/TRAIN/DRAFT_2/train_data_2012_to_2015.csv', index=False)\n",
    "test_data_2012_2015.to_csv('Filtered_Data/TEST/DRAFT_2/test_data_2012_2015.csv', index=False)\n",
    "\n",
    "# TRAIN 2020/2021\n",
    "train_data_2020_21.to_csv('Filtered_Data/TRAIN/DRAFT_2/train_data_2020_2021.csv', index=False)\n",
    "test_data_2020_21.to_csv('Filtered_Data/TEST/DRAFT_2/test_data_2020_2021.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T19:01:18.024958600Z",
     "start_time": "2024-04-16T19:01:03.664197200Z"
    }
   },
   "id": "fd2d74fb24b5aea",
   "execution_count": 149
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2c5f7adfdaf19abc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
